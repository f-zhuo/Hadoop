**有监督学习和无监督学习：**一般将数据集分为训练集和测试集，训练集用来生成模型，测试集用来检验模型。两者的差别在于训练集的结果有无答案

# 分类算法

给定一个对象 X ，将其划分到预定义的某一个类别 Yi 中。输入：X，输出：Y ，分为二分类和多分类问题

传统分类方法：分词，由关键词判断类型

问题：

* 可能引起歧义，比如关键词是苹果，那么属于科技文章还是农业文章

* 不能量化相似度，包含苹果这一关键词的文章有多大可能属于科技类

* 分词数量有限，不能穷举

由朴素贝叶斯解决

## 朴素贝叶斯

Naive Beyesian，分别计算待分类对象属于每个类别的概率，选择概率最大的类别作为最终输出

### 贝叶斯模型

$$
p(y_{i}|X)=\frac {p(X|yi)p(y_{i})} {p(X)}=\frac {p(y_{i})\prod p(x_{j}|yi)} {p(X)}
$$

其中：

`X={x1,x2,x3...}`表示对象，包含若干个特征

`yi`表示第i个类别

`P(X)`表示待分类对象自身的概率，为常数可忽略，`p(X)=p(x1,x2,x3...)=p(x1)p(x2)p(x3)...`（假设特征独立）

`P(yi)`表示每个类别的出现的概率，即先验概率，`p(y1)+p(y2)+...=1`

`P(X|yi)`表示每个类别产生该对象的概率

`P(xi|yi)`表示每个类别产生该特征的概率

### 最大似然估计

maximum likehood estimation/MLE，通过MLE求解贝叶斯的分类问题：给定 X ，计算所有的 p(yi|X)，选择概率值最大的yi作为输出

例：X={ 国内，投资，市场，。。。}，Y={军事，科技，生活}
P(军事|X)= P(国内|军事)P(投资|军事)P(市场|军事 )…… P(军事)
同样计算P(科技|X)和P(生活|X) ，比较最大值作为分类输出

优点：

* 简单有效
* 结果是概率，对二值和多值同样适用

缺点：

* 独立性假设有时不合理

### 评估

混淆矩阵，详见LR

